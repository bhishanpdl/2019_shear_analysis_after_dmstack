{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></div><div class=\"lev1 toc-item\"><a href=\"#Useful-Scripts\" data-toc-modified-id=\"Useful-Scripts-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Useful Scripts</a></div><div class=\"lev1 toc-item\"><a href=\"#Remove-NaNs-from-dmstack-csv-to-get-txt\" data-toc-modified-id=\"Remove-NaNs-from-dmstack-csv-to-get-txt-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Remove NaNs from dmstack csv to get txt</a></div><div class=\"lev1 toc-item\"><a href=\"#Create-final_text.txt-using-IMCAT\" data-toc-modified-id=\"Create-final_text.txt-using-IMCAT-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create final_text.txt using IMCAT</a></div><div class=\"lev1 toc-item\"><a href=\"#Plot-gmsq-histogram-using-final_text.txt\" data-toc-modified-id=\"Plot-gmsq-histogram-using-final_text.txt-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Plot gmsq histogram using final_text.txt</a></div><div class=\"lev1 toc-item\"><a href=\"#Run-Script\" data-toc-modified-id=\"Run-Script-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Run Script</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Date: Nov 7, 2019\n",
    "\n",
    "final_text.txt is created by imcat program after merging four lsst files (m,m9,l,l9)\n",
    "after cleaning.\n",
    "\n",
    "**Usual Filtering**\n",
    "```python\n",
    "column ==> deblend_nChild == 0.0\n",
    "ellipticity ==> ellip < 1.5\n",
    "nans ==> if nans in cols_select, remomve row\n",
    "\n",
    "where,\n",
    "cols_select = ['base_SdssCentroid_x', 'base_SdssCentroid_y',\n",
    "       'base_SdssCentroid_xSigma','base_SdssCentroid_ySigma',\n",
    "       'ext_shapeHSM_HsmShapeRegauss_e1','ext_shapeHSM_HsmShapeRegauss_e2',\n",
    "        'base_SdssShape_flux']\n",
    "```\n",
    "\n",
    "**Check effects of flags**\n",
    "```python\n",
    "calib_psfCandidate == 0.0 # usual flag\n",
    "\n",
    "# check effect of other flags on number density in 0.5 < gmsq < 1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "pd.set_option('display.max_columns',200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_method_attributes(obj, ncols=7,start=None, inside=None):\n",
    "    \"\"\" Show all the attributes of a given method.\n",
    "    Example:\n",
    "    ========\n",
    "    show_method_attributes(list)\n",
    "     \"\"\"\n",
    "    lst = [elem for elem in dir(obj) if elem[0]!='_' ]\n",
    "    lst = [elem for elem in lst \n",
    "           if elem not in 'os np pd sys time psycopg2'.split() ]\n",
    "\n",
    "    if isinstance(start,str):\n",
    "        lst = [elem for elem in lst if elem.startswith(start)]\n",
    "        \n",
    "    if isinstance(start,tuple) or isinstance(start,list):\n",
    "        lst = [elem for elem in lst for start_elem in start\n",
    "               if elem.startswith(start_elem)]\n",
    "        \n",
    "    if isinstance(inside,str):\n",
    "        lst = [elem for elem in lst if inside in elem]\n",
    "        \n",
    "    if isinstance(inside,tuple) or isinstance(inside,list):\n",
    "        lst = [elem for elem in lst for inside_elem in inside\n",
    "               if inside_elem in elem]\n",
    "\n",
    "    return pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calib_detected'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_flags = json.load( open('dict_flags.json'))\n",
    "# dict_flags\n",
    "\n",
    "dict_flags['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NaNs from dmstack csv to get txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting b01_remove_nans_dmstack.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile b01_remove_nans_dmstack.py\n",
    "# Author  : Bhishan Poudel\n",
    "# Date    : July 5, 2019\n",
    "# Update  : Nov 7, 2019\n",
    "\n",
    "# Description:\n",
    "#===============\n",
    "# Remove nans from dmstack output csv files and\n",
    "# do some filterings to give txt files.\n",
    "#\n",
    "# Command: py b01_remove_nans_dmstack.py [0]\n",
    "#\n",
    "# Estimated time: 2min 10 sec\n",
    "#\n",
    "#\n",
    "# Input/Oputputs:\n",
    "#=================\n",
    "# inputs : ../data/dmstack_csv/*.csv  (100*4 csv files)\n",
    "# outputs: for True : dmstack_txt/dmstack_txt_0T/*.txt 225MB\n",
    "#          for False: dmstack_txt/dmstack_txt_0F/*.txt 225MB\n",
    "#\n",
    "# Filtering:\n",
    "#============\n",
    "\n",
    "# 1. column ==> deblend_nChild==0\n",
    "# 2. flag ==> calib_psfCandidate==False **Read flag from json**\n",
    "# 3. ellipticity  ==> e =  sqrt(e1^2 + e2^2) < 1.5\n",
    "# 4. selection ==> choose only few columns\n",
    "# 5. nans ==> remove nans from all selected columns\n",
    "# 6. delimiter ==> change delimiter from space to tab for imcat\n",
    "#\n",
    "#\n",
    "\n",
    "#\n",
    "# Note: \n",
    "# When reading columns ext_shapeHSM_HsmShapeRegauss_e1 and e2\n",
    "# we read them combinedly as g in IMCAT, so original\n",
    "# reduced shear will be g = g/2.\n",
    "#\n",
    "#\n",
    "# Tech note:\n",
    "# lst_flag_nums_str = '[0,1]'\n",
    "# lst_flag_nums = [0,1]\n",
    "# flag_nums_str = '0_1'\n",
    "# flag_nums_true_false_str = '0_1T' and '0_1F'\n",
    "#\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "\n",
    "# constants\n",
    "RANGE = 100\n",
    "\n",
    "# global variables\n",
    "dict_flags_all = json.load(open('dict_flags.json'))\n",
    "\n",
    "# arguments\n",
    "lst_flag_nums_str = sys.argv[1] # [0], [0,1] etc\n",
    "lst_flag_nums = eval(lst_flag_nums_str)\n",
    "str_flag_nums = '_'.join([str(i) for i in lst_flag_nums]) # '0_1'\n",
    "\n",
    "odir_txtT = 'dmstack_txt/' + 'dmstack_txt_'+ str_flag_nums + 'T'\n",
    "odir_txtF = 'dmstack_txt/' + 'dmstack_txt_'+ str_flag_nums + 'F' \n",
    "\n",
    "# create output folder if not exist\n",
    "if not os.path.isdir('dmstack_txt'):\n",
    "    os.makedirs('dmstack_txt')\n",
    "    \n",
    "if not os.path.isdir(odir_txtT):\n",
    "    os.makedirs(odir_txtT)\n",
    "    \n",
    "if not os.path.isdir(odir_txtF):\n",
    "    os.makedirs(odir_txtF)\n",
    "\n",
    "def remove_nans(ifile,file_number, flag_TF):\n",
    "    \"\"\" Remove nans and filter data from dmstack output csv file.\n",
    "\n",
    "    There are 90 flags col0 to col89\n",
    "    col90 is id is first column 'id'\n",
    "\n",
    "    There are 90 flags and 77 columns.\n",
    "    We exclude first column 'flags' and have 76 columns\n",
    "    In total there are 90 + 76 = 166 columns.\n",
    "\n",
    "    Columns selected:\n",
    "    1   :  calib_psfCandidate (for filtering only)\n",
    "    94  :  deblend_nChild (for filtering only)\n",
    "    90  :  id\n",
    "    102 :  base_SdssCentroid_x\n",
    "    103 :  base_SdssCentroid_y\n",
    "    104 :  base_SdssCentroid_xSigma\n",
    "    105 :  base_SdssCentroid_ySigma\n",
    "    127 :  ext_shapeHSM_HsmShapeRegauss_e1\n",
    "    128 :  ext_shapeHSM_HsmShapeRegauss_e2\n",
    "    114 :  ext_shapeHSM_HsmShapeRegauss_sigma\n",
    "\n",
    "    # Added later for radius calculation\n",
    "    133: 'ext_shapeHSM_HsmSourceMoments_xx',\n",
    "    134: 'ext_shapeHSM_HsmSourceMoments_yy',\n",
    "    135: 'ext_shapeHSM_HsmSourceMoments_xy',\n",
    "\n",
    "    # This gives\n",
    "    radius = (xx*yy - xy**2)**1/4\n",
    "\n",
    "    # In the output  file we have\n",
    "    # 1          2    34   56             78     9     10    11\n",
    "    file_number, id,  x,y  xsigma,ysigma, e1,e2, ellip flux, radius\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(ifile, sep=\",\",low_memory=False)\n",
    "    df.columns = df.columns.str.lstrip('# ')\n",
    "    \n",
    "    # make dtype float\n",
    "    df = df.astype(float)\n",
    "\n",
    "    # extra filtering  \n",
    "    for num in lst_flag_nums:\n",
    "        col_flag =  dict_flags_all[ str(num)]\n",
    "        df = df[df[col_flag] == float(flag_TF) ]     \n",
    "\n",
    "    # select only few columns\n",
    "    usecols = [1, 94, 90, 102, 103, 104, 105, 127, 128, 114, 133,134,135]\n",
    "    df = df.iloc[:,usecols]\n",
    "    df = df.copy()\n",
    "\n",
    "    # make selected columns numeric\n",
    "    for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c],errors='coerce')\n",
    "\n",
    "\n",
    "    # filter the flag calib_psfCandidate==False\n",
    "    # not a star candidate\n",
    "    df = df.query('calib_psfCandidate == 0.0')\n",
    "\n",
    "    # filter the column deblend_nChild==0\n",
    "    # no child source after deblending\n",
    "    df = df.query('deblend_nChild == 0.0')\n",
    "\n",
    "    # clean out unphysical results\n",
    "    # e1^2 + e2^2 < 1.5^2\n",
    "    df = df.copy()\n",
    "    df['ellip'] = (df['ext_shapeHSM_HsmShapeRegauss_e1'] ** 2 +\n",
    "                   df['ext_shapeHSM_HsmShapeRegauss_e2'] ** 2)**0.5\n",
    "    df = df.query('ellip < 1.5')\n",
    "\n",
    "    # calculate radius of ellipse using HSM moments\n",
    "    # radius**4 = xx*yy - xy**2\n",
    "    df['radius'] =  df.eval(\"\"\" ( (ext_shapeHSM_HsmSourceMoments_xx *  ext_shapeHSM_HsmSourceMoments_yy) \\\n",
    "                                              -  (ext_shapeHSM_HsmSourceMoments_xy**2 ) )**0.25 \"\"\")\n",
    "\n",
    "    # add a new column with file_number\n",
    "    df['file_number'] = file_number\n",
    "\n",
    "    # take only required columns\n",
    "    cols_select = ['file_number', 'id',\n",
    "           'base_SdssCentroid_x', 'base_SdssCentroid_y',\n",
    "           'base_SdssCentroid_xSigma','base_SdssCentroid_ySigma',\n",
    "           'ext_shapeHSM_HsmShapeRegauss_e1','ext_shapeHSM_HsmShapeRegauss_e2',\n",
    "           'ellip', 'base_SdssShape_flux',  'radius'\n",
    "           ]\n",
    "\n",
    "    df = df[cols_select]\n",
    "\n",
    "    # drop all nans\n",
    "    df = df.dropna()\n",
    "\n",
    "    # write txt file with commented header\n",
    "    prefix = ' '*2\n",
    "    header_line = prefix.join(cols_select)\n",
    "\n",
    "    # from: ../data/dmstack_csv/src_lsst_mono_z1.5_000.csv\n",
    "    # to  : dmstack_txt/dmstack_txt_flag_0T/src_lsst_mono_z1.5_000.txt\n",
    "    #       dmstack_txt/dmstack_txt_flag_0F/src_lsst_mono_z1.5_000.txt\n",
    "    \n",
    "    dmstack_txt = odir_txtT if flag_TF == 1 else odir_txtF\n",
    "    ofile = ifile.replace('../data/dmstack_csv', dmstack_txt)\n",
    "    ofile = ofile.replace('.csv', '.txt')\n",
    "    np.savetxt(ofile,df.values,header=header_line,delimiter='\\t')\n",
    "\n",
    "def func1():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number, 0)\n",
    "        remove_nans(ifile, file_number, 1)\n",
    "\n",
    "def func2():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst90_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number, 0)\n",
    "        remove_nans(ifile, file_number, 1)\n",
    "\n",
    "def func3():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst_mono_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number, 0)\n",
    "        remove_nans(ifile, file_number, 1)\n",
    "\n",
    "def func4():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst_mono90_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number, 0)\n",
    "        remove_nans(ifile, file_number, 1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p1 = Process(target=func1)\n",
    "    p1.start()\n",
    "\n",
    "    p2 = Process(target=func2)\n",
    "    p2.start()\n",
    "\n",
    "    p3 = Process(target=func3)\n",
    "    p3.start()\n",
    "\n",
    "    p4 = Process(target=func4)\n",
    "    p4.start()\n",
    "\n",
    "    # join them all\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dmstack_txt/src_lsst_mono_z1.5_000_flag0.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ofile = 'dmstack_txt/src_lsst_mono_z1.5_000.csv'\n",
    "flag_01 = 0\n",
    "ofile.replace('.csv', f'_flag{flag_01}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final_text.txt using IMCAT\n",
    "```bash\n",
    "bash b02_combine_four_txts_to_lc_catalog.sh\n",
    "\n",
    "Created: final/final_000.cat\n",
    "Created: final/final_099.cat\n",
    "\n",
    "readcathead: file format error # we get this if we get error.\n",
    "\n",
    "Date: Nov 7, 2019\n",
    "I got redcathead error\n",
    "Fix: I forgot to delete catalogs/*.cat and final/*.cat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>589.8035</td>\n",
       "      <td>45.0719</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>-0.6785</td>\n",
       "      <td>0.890734</td>\n",
       "      <td>1882.7064</td>\n",
       "      <td>3.447925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1336.9200</td>\n",
       "      <td>55.5085</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>-1.0599</td>\n",
       "      <td>-0.5366</td>\n",
       "      <td>1.187993</td>\n",
       "      <td>10106.4629</td>\n",
       "      <td>3.917561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1          2        3       4       5       6       7         8   \\\n",
       "0  99.0  37.0   589.8035  45.0719  0.1933  0.1974  0.5771 -0.6785  0.890734   \n",
       "1  99.0  39.0  1336.9200  55.5085  0.0589  0.0847 -1.0599 -0.5366  1.187993   \n",
       "\n",
       "           9         10  \n",
       "0   1882.7064  3.447925  \n",
       "1  10106.4629  3.917561  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../a18_nov1_2019/dmstack_txt/src_lsst90_z1.5_099.txt',sep=r'\\t',skiprows=1,header=None,engine='python')\n",
    "\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>99.0</td>\n",
       "      <td>7643.0</td>\n",
       "      <td>993.2342</td>\n",
       "      <td>3218.5874</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.3388</td>\n",
       "      <td>1.0255</td>\n",
       "      <td>1.080017</td>\n",
       "      <td>19742.3352</td>\n",
       "      <td>4.268948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>99.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>988.2575</td>\n",
       "      <td>3241.1116</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.897350</td>\n",
       "      <td>5303.3168</td>\n",
       "      <td>4.461064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1         2          3       4       5       6       7   \\\n",
       "1805  99.0  7643.0  993.2342  3218.5874  0.0264  0.0251  0.3388  1.0255   \n",
       "1806  99.0  7650.0  988.2575  3241.1116  0.1980  0.1320  0.8632  0.2452   \n",
       "\n",
       "            8           9         10  \n",
       "1805  1.080017  19742.3352  4.268948  \n",
       "1806  0.897350   5303.3168  4.461064  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('dmstack_txt/src_lsst90_z1.5_099.txt',sep=r'\\t',skiprows=1,header=None,engine='python')\n",
    "\n",
    "df2.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot gmsq histogram using final_text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting b03_plot_gmsq.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile b03_plot_gmsq.py\n",
    "# Author: Bhishan Poudel\n",
    "# Date:  Nov 7, 2019\n",
    "# Command: py b03_plot_gmsq.py [0]\n",
    "\n",
    "import scipy\n",
    "import os,sys,json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "pd.set_option('display.max_columns',200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# global variables\n",
    "dict_flags_all = json.load(open('dict_flags.json'))\n",
    "\n",
    "# arguments\n",
    "lst_flag_nums_str = sys.argv[1] # [0], [0,1] etc\n",
    "lst_flag_nums = eval(lst_flag_nums_str)\n",
    "\n",
    "ofile_whole = ['results/flag/flag_' + '_'.join([str(i) for i in lst_flag_nums])][0] \n",
    "ofile_whole = ofile_whole + '.png'\n",
    "\n",
    "ofile_zoom = ['results/zoom/zoom_' + '_'.join([str(i) for i in lst_flag_nums])][0] \n",
    "ofile_zoom = ofile_zoom + '.png'\n",
    "\n",
    "ofile_text = ['results/text/zoom_' + '_'.join([str(i) for i in lst_flag_nums])][0] \n",
    "ofile_text = ofile_text + '.txt'\n",
    "\n",
    "if not os.path.isdir('results'):\n",
    "    os.makedirs('results')\n",
    "\n",
    "\n",
    "#===============================================================================\n",
    "colnames = \"\"\"fN[0][0]       fN[1][0]       fN[2][0]       fN[3][0]\n",
    "id[0][0]       id[1][0]       id[2][0]       id[3][0]\n",
    "x[0] x[1]     \n",
    "errx[0][0]     errx[0][1]     errx[1][0]     errx[1][1]\n",
    "errx[2][0]     errx[2][1]     errx[3][0]     errx[3][1]\n",
    "g[0][0]        g[0][1]        g[1][0]        g[1][1] \n",
    "g[2][0]        g[2][1]        g[3][0]        g[3][1]\n",
    "ellip[0][0]    ellip[1][0]    ellip[2][0]    ellip[3][0]\n",
    "flux[0][0]     flux[1][0]     flux[2][0]     flux[3][0]\n",
    "radius[0][0]   radius[1][0]   radius[2][0]   radius[3][0]\n",
    "gm[0]          gm[1]          gc[0]          gc[1]\n",
    "\"\"\".split()\n",
    "\n",
    "colnames = [i.strip() for i in colnames]\n",
    "\n",
    "#===============================================================================\n",
    "# final_text is obtained from imcat after combining m,m9,l,l9 text files\n",
    "df = pd.read_csv('final/final_text.txt',sep=r'\\s+',\n",
    "                 comment='#',header=None)\n",
    "\n",
    "df.columns = colnames\n",
    "\n",
    "#===============================================================================\n",
    "# Find total flux, gm**2 and gc**2\n",
    "df['flux'] = df['flux[0][0]'] + df['flux[1][0]'] + df['flux[2][0]'] + df['flux[3][0]']\n",
    "df['gm_sq'] = df['gm[0]']**2 + df['gm[1]']**2\n",
    "df['gc_sq'] = df['gc[0]']**2 + df['gc[1]']**2\n",
    "\n",
    "#===============================================================================\n",
    "a,b = 0.5, 1.1\n",
    "df_bad = df.query(\" @a < gm_sq < @b\")\n",
    "\n",
    "\n",
    "obj_all = 'all objects = {:,}'.format(len(df))\n",
    "obj_bad = 'bad objects = {:,}'.format(len(df_bad))\n",
    "per_bad = 'bad objects percentage = {:.4f}% '.format(len(df_bad)/len(df)*100)\n",
    "\n",
    "with open(ofile_text,'w') as fo:\n",
    "    line = obj_all + ' ' + obj_bad + ' ' + per_bad + '\\n'\n",
    "    fo.write(line)\n",
    "\n",
    "# whole figure Histogram\n",
    "#===============================================================================\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,12))\n",
    "\n",
    "# hist + density\n",
    "g = sns.distplot(df['gm_sq'], bins=60, ax=ax, norm_hist=True, kde=True)\n",
    "\n",
    "# text\n",
    "ax.text(0.6,0.4,obj_all)\n",
    "ax.text(0.6,0.6,obj_bad)\n",
    "ax.text(0.6,0.8,per_bad)\n",
    "\n",
    "# labels\n",
    "ax.set_xlabel('gm_sq')\n",
    "ax.set_ylabel('arbitrary density unit')\n",
    "\n",
    "# limits\n",
    "ax.set_xlim(0,1.5)\n",
    "\n",
    "# ticks\n",
    "ax.set_xticks(np.arange(0,1.5,0.1))\n",
    "\n",
    "\n",
    "# vr lines\n",
    "ax.axvline(x=a,c='r',ls='--',label=f'gmsq = {a}')\n",
    "ax.axvline(x=b,c='r',ls='--', label=f'gmsq = {b}')\n",
    "\n",
    "# legends\n",
    "ax.legend()\n",
    "plt.suptitle('Histogram for gmsq')\n",
    "plt.savefig(ofile_whole)\n",
    "plt.close()\n",
    "\n",
    "# zoom y-axis\n",
    "#================================================\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,12))\n",
    "df['gm_sq'].hist(ax=ax, label='gm_sq',bins=60)\n",
    "\n",
    "# text\n",
    "ax.text(0.6,4000,obj_all)\n",
    "ax.text(0.6,4200,obj_bad)\n",
    "ax.text(0.6,4400,per_bad)\n",
    "\n",
    "# labels\n",
    "ax.set_xlabel('gm_sq')\n",
    "ax.set_ylabel('count')\n",
    "\n",
    "# limits\n",
    "ax.set_xlim(0,1.5)\n",
    "\n",
    "\n",
    "# vr lines\n",
    "ax.axvline(x=a,c='r',ls='--',label=f'gmsq = {a}')\n",
    "ax.axvline(x=b,c='r',ls='--', label=f'gmsq = {b}')\n",
    "\n",
    "# legends\n",
    "ax.legend()\n",
    "plt.suptitle('Histogram for gmsq')\n",
    "\n",
    "# ticks\n",
    "y_top = 10_000\n",
    "ax.set_xlim(0.1,1.5)\n",
    "ax.set_ylim(0,y_top)\n",
    "ax.set_yticks(np.arange(0,y_top,200))\n",
    "ax.set_xticks(np.arange(0,1.5,0.1))\n",
    "\n",
    "for x in np.arange(0,y_top,200):\n",
    "    ax.axhline(y=x,color='g',alpha=0.3)\n",
    "\n",
    "plt.savefig(ofile_zoom)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! /Users/poudel/Library/Enthought/Canopy/edm/envs/deeplr/bin/python b03_plot_gmsq.py [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat ../a18_nov1_2019/run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > run.sh << EOL\n",
    "# Estimated time \n",
    "# Nov 7 2019:  [ 4h 46m 18s413 | Nov 08 12:34AM ]\n",
    "for i in {0..89}                                                                \n",
    "   do\n",
    "        lst=\"[\\$i]\" &&\n",
    "        echo \"Estimated time: 3 min 45 seconds.\" &&\n",
    "        echo \"Cleaning old files: catalogs, final and dmstack_txt\" &&\n",
    "        rm -rf catalogs/*.cat final/* dmstack_txt/* &&\n",
    "\n",
    "        # remove nans from dmstack csv and create txt\n",
    "        echo \"Removing nans\" &&\n",
    "        /Users/poudel/Library/Enthought/Canopy/edm/envs/deeplr/bin/python b01_remove_nans_dmstack.py \\$lst &&\n",
    "\n",
    "        # read 100*4 tab separated txt files, and create only 100 cats\n",
    "        # and one big final final/final_text.txt using imcat\n",
    "        echo \"Creating cat files\" &&\n",
    "        bash b02_combine_four_txts_to_lc_catalog.sh &&\n",
    "\n",
    "        # read final_text.txt and create gmsq histogram plot\n",
    "        echo \"Creating gmsq plot\"\n",
    "        /Users/poudel/Library/Enthought/Canopy/edm/envs/deeplr/bin/python b03_plot_gmsq.py \\$lst                                                \n",
    "done;\n",
    "\n",
    "EOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in {0..1}                                                                \n",
      "   do\n",
      "        lst=\"[$i]\" &&\n",
      "        echo \"Estimated time: 3 min 45 seconds.\" &&\n",
      "        echo \"Cleaning old files: catalogs, final and dmstack_txt\" &&\n",
      "        rm -rf catalogs/*.cat final/* dmstack_txt/* &&\n",
      "\n",
      "        # remove nans from dmstack csv and create txt\n",
      "        echo \"Removing nans\" &&\n",
      "        /Users/poudel/Library/Enthought/Canopy/edm/envs/deeplr/bin/python b01_remove_nans_dmstack.py $lst &&\n",
      "\n",
      "        # read 100*4 tab separated txt files, and create only 100 cats\n",
      "        # and one big final final/final_text.txt using imcat\n",
      "        echo \"Creating cat files\" &&\n",
      "        bash b02_combine_four_txts_to_lc_catalog.sh &&\n",
      "\n",
      "        # read final_text.txt and create gmsq histogram plot\n",
      "        echo \"Creating gmsq plot\"\n",
      "        /Users/poudel/Library/Enthought/Canopy/edm/envs/deeplr/bin/python b03_plot_gmsq.py $lst                                                \n",
      "done;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "for i in {0..10}                                                                \n",
    "   do\n",
    "      lst=\"[$i]\"\n",
    "      echo \"$lst\";                                                   \n",
    "done;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dmstack_txt/dmstack_txt_0_1T'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_flag_nums = [0,1]\n",
    "str_flag_nums = '_'.join([str(i) for i in a])\n",
    "\n",
    "\n",
    "odir_txt0 = 'dmstack_txt/' + 'dmstack_txt_'+ str_flag_nums + 'T'\n",
    "odir_txt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\r\n",
      "[1]\r\n",
      "[2]\r\n",
      "[3]\r\n",
      "[4]\r\n",
      "[5]\r\n",
      "[6]\r\n",
      "[7]\r\n",
      "[8]\r\n",
      "[9]\r\n",
      "[10]\r\n"
     ]
    }
   ],
   "source": [
    "!bash test.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final/final_0T\n",
      "final/final_0F\n",
      "final/final_1T\n",
      "final/final_1F\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nums=\"[0,1]\"\n",
    "nums=\"${nums:1:${#nums}-2}\" # 0,1\n",
    "nums=($(echo \"$nums\" | tr ',' '\\n'))\n",
    "\n",
    "# echo \"${nums[0]}\"\n",
    "\n",
    "for num in \"${nums[@]}\"\n",
    "do\n",
    "    for t in T F\n",
    "    do\n",
    "        final=\"final/final_\"\"$num\"\"$t\"\n",
    "        echo \"$final\"\n",
    "    done;\n",
    "done;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "45px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
