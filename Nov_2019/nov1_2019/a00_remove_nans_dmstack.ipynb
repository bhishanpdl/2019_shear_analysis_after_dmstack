{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#Script\" data-toc-modified-id=\"Script-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Script</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Date: Nov 1, 2019  \n",
    "- DMSTACK gives csv files with lots of nans\n",
    "- We need to remove nans, and select few columns, and do some cleanings.\n",
    "- Previously, after doing cleaning and using IMCAT to combine lsst and mono\n",
    "  I got final_text.txt file which have columns like gm0 and gm1.\n",
    "- I plotted the number density of gmsq = gm0**2 + gm1**2 and see that\n",
    "  there was bump in number density when 0.7 < gmsq < 1.0.\n",
    "- About 10% objects were bad objects (i.e. 0.7 < gmsq < 1.0.\n",
    "- I looked at the objects with these density range and looked at the dmstack flags\n",
    "  which cause these objects and found that if all these 28 flags (out of 90 flags) are\n",
    "  all zero, then the object is bad otherwise not.\n",
    "\n",
    "```python\n",
    "cols_imp = ['base_GaussianCentroid_flag',\n",
    "       'base_GaussianCentroid_flag_resetToPeak', 'base_SdssCentroid_flag',\n",
    "       'base_SdssCentroid_flag_edge',\n",
    "       'base_SdssCentroid_flag_almostNoSecondDerivative',\n",
    "       'base_SdssCentroid_flag_notAtMaximum',\n",
    "       'base_SdssCentroid_flag_resetToPeak',\n",
    "       'base_SdssShape_flag_unweightedBad',\n",
    "       'base_SdssShape_flag_unweighted', 'base_SdssShape_flag_maxIter',\n",
    "       'ext_shapeHSM_HsmPsfMoments_flag',\n",
    "       'ext_shapeHSM_HsmPsfMoments_flag_galsim',\n",
    "       'ext_shapeHSM_HsmSourceMoments_flag',\n",
    "       'ext_shapeHSM_HsmSourceMoments_flag_galsim',\n",
    "       'base_CircularApertureFlux_3_0_flag',\n",
    "       'base_CircularApertureFlux_4_5_flag',\n",
    "       'base_CircularApertureFlux_4_5_flag_sincCoeffsTruncated',\n",
    "       'base_CircularApertureFlux_6_0_flag',\n",
    "       'base_CircularApertureFlux_6_0_flag_sincCoeffsTruncated',\n",
    "       'base_CircularApertureFlux_9_0_flag',\n",
    "       'base_CircularApertureFlux_12_0_flag',\n",
    "       'base_CircularApertureFlux_12_0_flag_apertureTruncated',\n",
    "       'base_CircularApertureFlux_17_0_flag',\n",
    "       'base_CircularApertureFlux_17_0_flag_apertureTruncated',\n",
    "       'base_GaussianFlux_flag', 'base_PsfFlux_flag',\n",
    "       'base_PsfFlux_flag_edge', 'base_ClassificationExtendedness_flag']\n",
    "\n",
    "```\n",
    "\n",
    "**Attempt 1**\n",
    "Usual filtering:\n",
    "```\n",
    "all objects = 183,832\n",
    "bad objects = 23,444\n",
    "bad objects percentage = 12.75% \n",
    "```\n",
    "![](results/a01_orig_gmsq_kde_whole_data.png)\n",
    "![](results/a02_orig_gmsq_kde_zoom.png)\n",
    "\n",
    "\n",
    "**Attempt 2**\n",
    "Use all those 28 filterings.\n",
    "This gives extremely low number of objects. If we exclude nans there are ZERO\n",
    "objects. So I will include nans in errx and erry.\n",
    "```\n",
    "if all 28 flags == False:\n",
    "    object is good (0.6 < gmsq < 1.0)\n",
    "else:\n",
    "    object is bad.\n",
    "    \n",
    "    \n",
    "all objects = 183,830\n",
    "bad objects = 23,444\n",
    "bad objects percentage = 12.75% \n",
    "```\n",
    "![](results/b01_gmsq_kde_whole_data.png)\n",
    "![](results/b02_gmsq_kde_zoom.png)\n",
    "\n",
    "\n",
    "**Attempt 3**\n",
    "Take few columns from 28 features and choose only rows\n",
    "where these features equal zero.\n",
    "```\n",
    "all objects = 183,830\n",
    "bad objects = 23,444\n",
    "bad objects percentage = 12.75% \n",
    "\n",
    "```\n",
    "![](results/c01_few_gmsq_kde_whole_data.png)\n",
    "![](results/c02_few_gmsq_kde_zoom.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting b00_remove_nans_dmstack.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile b00_remove_nans_dmstack.py\n",
    "# Author  : Bhishan Poudel\n",
    "# Date    : July 5, 2019\n",
    "# Update  : Nov 6, 2019 (created shear column)\n",
    "\n",
    "# Description:\n",
    "#===============\n",
    "# Remove nans from dmstack output csv files and do some filterings to give\n",
    "# txt files.\n",
    "#\n",
    "# Input/Oputputs:\n",
    "#=================\n",
    "# Reads all *.csv files and creates *.txt from them.\n",
    "#\n",
    "#\n",
    "# Filtering:\n",
    "#============\n",
    "# 1. flag calib_psfCandidate==False\n",
    "# 2. column deblend_nChild==0\n",
    "# 3. ellipticity e =  sqrt(e1^2 + e2^2) < 1.5\n",
    "# 4. choose only few columns given below\n",
    "# 5. remove nans from all these columns\n",
    "# 6. change delimiter to tab.\n",
    "#\n",
    "#\n",
    "# Usage:\n",
    "#=======\n",
    "# python b00_remove_nans_dmstack.py\n",
    "#\n",
    "# Estimated time: 1m 2s\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "\n",
    "RANGE = 100\n",
    "\n",
    "# important columns\n",
    "cols_imp = ['base_GaussianCentroid_flag',\n",
    "       'base_GaussianCentroid_flag_resetToPeak', 'base_SdssCentroid_flag',\n",
    "       'base_SdssCentroid_flag_edge',\n",
    "       'base_SdssCentroid_flag_almostNoSecondDerivative',\n",
    "       'base_SdssCentroid_flag_notAtMaximum',\n",
    "       'base_SdssCentroid_flag_resetToPeak',\n",
    "       'base_SdssShape_flag_unweightedBad',\n",
    "       'base_SdssShape_flag_unweighted', 'base_SdssShape_flag_maxIter',\n",
    "       'ext_shapeHSM_HsmPsfMoments_flag',\n",
    "       'ext_shapeHSM_HsmPsfMoments_flag_galsim',\n",
    "       'ext_shapeHSM_HsmSourceMoments_flag',\n",
    "       'ext_shapeHSM_HsmSourceMoments_flag_galsim',\n",
    "       'base_CircularApertureFlux_3_0_flag',\n",
    "       'base_CircularApertureFlux_4_5_flag',\n",
    "       'base_CircularApertureFlux_4_5_flag_sincCoeffsTruncated',\n",
    "       'base_CircularApertureFlux_6_0_flag',\n",
    "       'base_CircularApertureFlux_6_0_flag_sincCoeffsTruncated',\n",
    "       'base_CircularApertureFlux_9_0_flag',\n",
    "       'base_CircularApertureFlux_12_0_flag',\n",
    "       'base_CircularApertureFlux_12_0_flag_apertureTruncated',\n",
    "       'base_CircularApertureFlux_17_0_flag',\n",
    "       'base_CircularApertureFlux_17_0_flag_apertureTruncated',\n",
    "       'base_GaussianFlux_flag', 'base_PsfFlux_flag',\n",
    "       'base_PsfFlux_flag_edge', 'base_ClassificationExtendedness_flag']\n",
    "\n",
    "def remove_nans(ifile,file_number):\n",
    "    \"\"\" Remove nans and filter data from dmstack output csv file.\n",
    "\n",
    "    There are 90 flags col0 to col89\n",
    "    col90 is id is first column 'id'\n",
    "\n",
    "    There are 90 flags and 77 columns.\n",
    "    We exclude first column 'flags' and have 76 columns\n",
    "    In total there are 90 + 76 = 166 columns.\n",
    "\n",
    "    Columns selected:\n",
    "    1   :  calib_psfCandidate (for filtering only)\n",
    "    94  :  deblend_nChild (for filtering only)\n",
    "    90  :  id\n",
    "    102 :  base_SdssCentroid_x\n",
    "    103 :  base_SdssCentroid_y\n",
    "    104 :  base_SdssCentroid_xSigma\n",
    "    105 :  base_SdssCentroid_ySigma\n",
    "    127 :  ext_shapeHSM_HsmShapeRegauss_e1\n",
    "    128 :  ext_shapeHSM_HsmShapeRegauss_e2\n",
    "    114 :  ext_shapeHSM_HsmShapeRegauss_sigma\n",
    "\n",
    "    # Added later for radius calculation\n",
    "    133: 'ext_shapeHSM_HsmSourceMoments_xx',\n",
    "    134: 'ext_shapeHSM_HsmSourceMoments_yy',\n",
    "    135: 'ext_shapeHSM_HsmSourceMoments_xy',\n",
    "\n",
    "    # This gives\n",
    "    radius = (xx*yy - xy**2)**1/4\n",
    "\n",
    "    # In the output  file we have\n",
    "    # 1          2    34   56             78     9     10    11\n",
    "    file_number, id,  x,y  xsigma,ysigma, e1,e2, shear flux, radius\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(ifile, sep=\",\",low_memory=False)\n",
    "    \n",
    "    # make dtype float\n",
    "    df = df.astype(float)\n",
    "    \n",
    "    # filter object with not all 28 flags as False\n",
    "    # i.e. at least one of the 28 flags is True\n",
    "    cond = df[cols_imp].eq(0.0).all(axis=1)\n",
    "    df = df.loc[cond]\n",
    "    # 28 features gave extreme bad peak at 0.7 to 1.0\n",
    "    # that was not good.\n",
    "\n",
    "    # extra filtering  \n",
    "#     df = df.query('ext_shapeHSM_HsmPsfMoments_flag_galsim == 0')\n",
    "#     df = df.query('base_SdssShape_flag_unweightedBad == 0')\n",
    "#     df = df.query('ext_shapeHSM_HsmSourceMoments_flag_galsim == 0')\n",
    "#     df = df.query('base_GaussianFlux_flag == 0')\n",
    "#     df = df.query('base_SdssShape_flag_maxIter == 0')\n",
    "#     df = df.query('base_GaussianCentroid_flag == 0')\n",
    "#     df = df.query('base_GaussianCentroid_flag_resetToPeak == 0')\n",
    "#     df = df.query('base_PsfFlux_flag_edge == 0')\n",
    "#     df = df.query('base_SdssCentroid_flag_edge == 0')\n",
    "#     df = df.query('base_PsfFlux_flag == 0')\n",
    "#     df = df.query('base_CircularApertureFlux_3_0_flag == 0')\n",
    "#     df = df.query('base_SdssCentroid_flag == 0')\n",
    "#     df = df.query('base_CircularApertureFlux_17_0_flag == 0')\n",
    "#     df = df.query('ext_shapeHSM_HsmPsfMoments_flag == 0')\n",
    "#     df = df.query('ext_shapeHSM_HsmSourceMoments_flag == 0')\n",
    "#     df = df.query('base_ClassificationExtendedness_flag == 0')\n",
    "#     df = df.query('base_SdssShape_flag_unweighted == 0')\n",
    "\n",
    "    \n",
    "    usecols = [1, 94, 90, 102, 103, 104, 105, 127, 128, 114, 133,134,135]\n",
    "    df = df.iloc[:,usecols]\n",
    "\n",
    "    for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c],errors='coerce')\n",
    "\n",
    "\n",
    "    # filter the flag calib_psfCandidate==False\n",
    "    # not a star candidate\n",
    "    df = df.query('calib_psfCandidate == 0.0')\n",
    "\n",
    "    # filter the column deblend_nChild==0\n",
    "    # no child source after deblending\n",
    "    df = df.query('deblend_nChild == 0.0')\n",
    "\n",
    "    # clean out unphysical results\n",
    "    # e1^2 + e2^2 < 1.5^2\n",
    "    df['ellip'] = (df['ext_shapeHSM_HsmShapeRegauss_e1'] ** 2 + df['ext_shapeHSM_HsmShapeRegauss_e2'] ** 2)**0.5\n",
    "    df = df.query('ellip < 1.5')\n",
    "    df['shear'] = df['ellip']/2\n",
    "\n",
    "    df.drop('ellip',axis=1,inplace=True)\n",
    "\n",
    "    # calculate radius of ellipse using HSM moments\n",
    "    # radius**4 = xx*yy - xy**2\n",
    "    df['radius'] =  df.eval(\"\"\" ( (ext_shapeHSM_HsmSourceMoments_xx *  ext_shapeHSM_HsmSourceMoments_yy) \\\n",
    "                                              -  (ext_shapeHSM_HsmSourceMoments_xy**2 ) )**0.25 \"\"\")\n",
    "\n",
    "    # add a new column with file_number\n",
    "    df['file_number'] = file_number\n",
    "\n",
    "    # take only required columns\n",
    "    cols_select = ['file_number', 'id',\n",
    "           'base_SdssCentroid_x', 'base_SdssCentroid_y',\n",
    "           'base_SdssCentroid_xSigma','base_SdssCentroid_ySigma',\n",
    "           'ext_shapeHSM_HsmShapeRegauss_e1','ext_shapeHSM_HsmShapeRegauss_e2',\n",
    "           'shear', 'base_SdssShape_flux',  'radius'\n",
    "           ]\n",
    "\n",
    "    df = df[cols_select]\n",
    "\n",
    "    # drop all nans\n",
    "#     df = df.dropna()\n",
    "\n",
    "    # write txt file with commented header\n",
    "    prefix = ' '*2\n",
    "    header_line = prefix.join(cols_select)\n",
    "\n",
    "    # from: ../data/dmstack_csv/src_lsst_mono_z1.5_000.csv\n",
    "    # to  : dmstack_txt/src_lsst_mono_z1.5_000.txt\n",
    "    ofile = ifile.replace('../data/dmstack_csv', 'dmstack_txt')\n",
    "    ofile = ofile.replace('.csv', '.txt')\n",
    "    np.savetxt(ofile,df.values,header=header_line,delimiter='\\t')\n",
    "\n",
    "def func1():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number)\n",
    "\n",
    "def func2():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst90_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number)\n",
    "\n",
    "\n",
    "def func3():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst_mono_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number)\n",
    "\n",
    "\n",
    "def func4():\n",
    "    infiles = ['../data/dmstack_csv/src_lsst_mono90_z1.5_{:03d}.csv'.format(i) for i in range(RANGE)]\n",
    "    for ifile in infiles:\n",
    "        file_number = int(ifile.rstrip('.csv').split('_')[-1])\n",
    "        remove_nans(ifile, file_number)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p1 = Process(target=func1)\n",
    "    p1.start()\n",
    "\n",
    "    p2 = Process(target=func2)\n",
    "    p2.start()\n",
    "\n",
    "    p3 = Process(target=func3)\n",
    "    p3.start()\n",
    "\n",
    "    p4 = Process(target=func4)\n",
    "    p4.start()\n",
    "\n",
    "    # join them all\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
